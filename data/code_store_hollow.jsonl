{"id": "module_draft_genome", "content": "nextflow.enable.dsl=2\n\ninclude { step_2AS_mapping__bowtie } from '../steps/step_2AS_mapping__bowtie'\ninclude { step_2AS_mapping__ivar } from '../steps/step_2AS_mapping__ivar'\ninclude { step_4AN_genes__prokka } from '../steps/step_4AN_genes__prokka'\ninclude { step_4TY_lineage__pangolin } from '../steps/step_4TY_lineage__pangolin'\ninclude { extractKey; getEmpty } from '../functions/common.nf'\ninclude { getSingleInput;getReferenceOptional;getReference } from '../functions/parameters.nf'\n\ndef PROKKA_KINGDOM = 'Viruses'\n\nworkflow module_draft_genome {\n    take: \n        reads\n        reference \n        referenceGB\n    main:\n        reads.cross(reference) { extractKey(it) }.multiMap { \n            reads: it[0] // riscd, reads\n            refs:  it[1][1..3] // riscd, code, path\n        }.set { readsAndReferences }\n\n        step_2AS_mapping__bowtie(readsAndReferences.reads, readsAndReferences.refs)\n\n        consensus = step_2AS_mapping__ivar(readsAndReferences.reads, readsAndReferences.refs).consensus\n\n        consensus.cross(referenceGB) { extractKey(it) }.map { \n            [ it[0][0], it[0][1], PROKKA_KINGDOM, it[1][1], it[1][2], it[1][3] ] // riscd assembly kingdom riscd_ref refid refpath]\n\n        }.set { consensusKingdomReference }\n\n        step_4AN_genes__prokka(consensusKingdomReference)\n}\n\nworkflow  {\n    module_draft_genome(getSingleInput(), getReference('fa'), getReferenceOptional('gb'))\n}", "source_path": "modules/module_draft_genome.nf"}
{"id": "module_denovo", "content": "nextflow.enable.dsl=2\n\ninclude { step_1PP_hostdepl__bowtie } from '../steps/step_1PP_hostdepl__bowtie'\ninclude { step_2AS_denovo__spades } from '../steps/step_2AS_denovo__spades'\ninclude { extractKey; getEmpty } from '../functions/common.nf'\ninclude { getSingleInput;getHost } from '../functions/parameters.nf'\n\nworkflow module_denovo {\n    take: \n        trimmedReads\n        host \n    main:\n        trimmedReads.cross(host) { extractKey(it) }\n            .map { [ it[0][0], it[0][1], it[1][1] ] } //riscd, reads, host\n            .branch {\n                with_host: it[1][1]\n                without_host: true\n            }\n        .set { branchedTrimmed }\n\n        depleted = step_1PP_hostdepl__bowtie(branchedTrimmed.with_host)\n\n        ch_denovo_input = branchedTrimmed.without_host\n            .mix(depleted)\n            .map { it[0,1] } // Keep [riscd, reads]\n            \n        assembled = step_2AS_denovo__spades(ch_denovo_input)\n\n    emit:\n        assembled = assembled\n        depleted = depleted\n}\n\nworkflow {\n    module_denovo(getSingleInput(), getHost())\n}", "source_path": "modules/module_denovo.nf"}
{"id": "module_scaffolds_filtering", "content": "nextflow.enable.dsl=2\n\ninclude { step_2AS_filtering__seqio } from '../steps/step_2AS_filtering__seqio'\ninclude { step_3TX_species__vdabricate } from '../steps/step_3TX_species__vdabricate'\ninclude { extractKey } from '../functions/common.nf'\ninclude { getInput;getReference;getDS } from '../functions/parameters.nf'\n\nworkflow module_scaffolds_filtering {    \n    take: \n        assembled\n        reference \n        abricatedatabase \n    main:\n        assembled.cross(abricatedatabase) { extractKey(it) }\n            .map { \n                [ it[0][0], it[0][1], it[1][1] ] \n            }\n            .set { ch_scaffolds_db }\n\n        ch_calls = step_3TX_species__vdabricate(ch_scaffolds_db)\n\n        ch_calls.cross(assembled) { extractKey(it) }\n            .cross(reference) { extractKey(it) }\n            .multiMap { \n                calls: it[0][0]\n                assembly: it[0][1]\n                reference: it[1][1..3]\n            }\n            .set { ch_filt }\n\n        step_2AS_filtering__seqio(ch_filt.calls, ch_filt.assembly, ch_filt.reference)\n}\n\nworkflow {\n    ch_input = getInput()\n    ch_ref = getReference('fa')\n    ch_db = Channel.of([ getDS(), 'viruses_TREF' ])\n    module_scaffolds_filtering(ch_input, ch_ref, ch_db)\n}", "source_path": "modules/module_scaffolds_filtering.nf"}
{"id": "module_westnile", "content": "nextflow.enable.dsl=2\n\ninclude { step_4TY_lineage__westnile; getReferenceForLineage } from '../steps/step_4TY_lineage__westnile'\ninclude { step_2AS_mapping__ivar } from '../steps/step_2AS_mapping__ivar'\ninclude { extractKey } from '../functions/common.nf'\ninclude { getSingleInput } from '../functions/parameters.nf'\n\nworkflow module_westnile {\n    take: \n        reads        \n    main:\n        ch_lineage = step_4TY_lineage__westnile(reads)\n\n        reads.cross(ch_lineage) { extractKey(it) }\n            .multiMap { \n                reads: it[0]\n                reference: getReferenceForLineage(it[1][1])\n            }\n            .set { ch_ready }\n        \n        ivar_out = step_2AS_mapping__ivar(ch_ready.reads, ch_ready.reference)\n\n    emit:\n        consensus = ivar_out.consensus\n}\n\nworkflow {\n    ch_input = getSingleInput()\n    module_westnile(ch_input)\n}", "source_path": "modules/module_westnile.nf"}
{"id": "module_vdraft", "content": "nextflow.enable.dsl=2\n\ninclude { module_denovo } from '../modules/module_denovo'\ninclude { module_scaffolds_filtering } from '../modules/module_scaffolds_filtering'\ninclude { module_draft_genome } from '../modules/module_draft_genome'\ninclude { extractKey } from '../functions/common.nf'\ninclude { getSingleInput;getHost;getReference;getReferenceOptional;getDS } from '../functions/parameters.nf'\n\nworkflow module_vdraft {\n    take: \n        reads\n        host\n        reference\n        referenceGB\n        abricateDatabase\n    main:\n        denovo_out = module_denovo(reads, host)\n\n        denovo_out.assembled\n            .cross(reference) { extractKey(it) }\n            .cross(abricateDatabase) { extractKey(it) }\n            .multiMap { \n                assembly: it[0][0][0..1]\n                reference: it[0][1]\n                abricateDatabase: it[1]\n            }\n            .set { ch_scaff_filt }\n            \n        module_scaffolds_filtering(ch_scaff_filt.assembly, ch_scaff_filt.reference, ch_scaff_filt.abricateDatabase)\n        \n        denovo_out.depleted\n            .cross(reference) { extractKey(it) }\n            .cross(referenceGB) { extractKey(it) }\n            .multiMap {\n                depleted: it[0][0][0..1]\n                reference: it[0][1]\n                referenceGB: it[1]\n            }\n            .set { ch_draft }\n            \n        module_draft_genome(ch_draft.depleted, ch_draft.reference, ch_draft.referenceGB)\n}\n\nworkflow {\n    ch_in = getSingleInput()\n    ch_host = getHost()\n    ch_ref_fa = getReference('fa')\n    ch_ref_gb = getReferenceOptional('gb')\n    ch_db = Channel.of([ getDS(), 'viruses_TREF' ])\n    \n    module_vdraft(ch_in, ch_host, ch_ref_fa, ch_ref_gb, ch_db)\n}", "source_path": "modules/module_vdraft.nf"}
{"id": "module_typing_bacteria", "content": "nextflow.enable.dsl=2\n\ninclude { step_2AS_mapping__bowtie } from '../steps/step_2AS_mapping__bowtie'\ninclude { step_3TX_species__kmerfinder; getBacterialReferencePath } from '../steps/step_3TX_species__kmerfinder'\ninclude { step_4AN_genes__prokka } from '../steps/step_4AN_genes__prokka'\ninclude { step_4AN_AMR__abricate } from '../steps/step_4AN_AMR__abricate'\ninclude { step_4AN_AMR__staramr } from '../steps/step_4AN_AMR__staramr'\ninclude { step_4TY_cgMLST__chewbbaca } from '../steps/step_4TY_cgMLST__chewbbaca'\ninclude { step_4TY_MLST__mlst } from '../steps/step_4TY_MLST__mlst'\ninclude { step_4TY_flaA__flaA } from '../steps/step_4TY_flaA__flaA'\ninclude { csv2map; extractKey; getEmpty } from '../functions/common.nf'\ninclude { getTrimmedReads; getAssembly } from '../functions/parameters.nf'\n\nworkflow module_typing_bacteria {\n    take: \n        trimmed\n        assembly\n    main:\n        kmer_results = step_3TX_species__kmerfinder(assembly)\n        ch_assigned = kmer_results.assigned_species\n      \n        if (!params.skip_bestref_mapping) {\n            trimmed.cross(ch_assigned) { extractKey(it) }\n                .multiMap { \n                    trimmed: it[0]\n                    species: it[1][1]\n                    referencePath: it[1][2]\n                }\n                .set { ch_mapping }\n            \n            step_2AS_mapping__bowtie(ch_mapping.trimmed, ch_mapping.referencePath)\n        } \n\n        step_4AN_AMR__abricate(assembly)\n\n        ch_prokka_in = assembly.map { [ it[0], it[1], 'Bacteria', '-', '-', getEmpty() ] }\n        step_4AN_genes__prokka(ch_prokka_in)\n\n        assembly.cross(ch_assigned) { extractKey(it) }\n            .multiMap { \n                assembly: it[0]\n                species: it[1][1]\n            }\n            .set { ch_typing }\n\n        step_4AN_AMR__staramr(ch_typing.assembly, ch_typing.species)\n        step_4TY_MLST__mlst(ch_typing.assembly)\n        step_4TY_flaA__flaA(ch_typing.assembly, ch_typing.species)\n        step_4TY_cgMLST__chewbbaca(ch_typing.assembly, ch_typing.species, '')\n    \n    emit:\n        genus_species = ch_assigned\n}\n\nworkflow {\n    ch_trimmed = getTrimmedReads(true)\n    ch_assembly = getAssembly()\n    module_typing_bacteria(ch_trimmed, ch_assembly)\n}", "source_path": "modules/module_typing_bacteria.nf"}
{"id": "module_segmented", "content": "nextflow.enable.dsl=2\n\ninclude { extractKey } from '../functions/common.nf'\ninclude { step_2AS_mapping__ivar } from '../steps/step_2AS_mapping__ivar'\ninclude { getSingleInput;getReferences } from '../functions/parameters.nf'\n\nworkflow module_segmented {\n    take: \n        reads\n        reference \n    main:\n        ivar_results = step_2AS_mapping__ivar(reads, reference)\n    emit:\n        consensus = ivar_results.consensus\n}\n\nworkflow prepare_inputs {\n    take:\n        raw_reads\n        raw_refs\n    main:\n        raw_reads.cross(raw_refs) { extractKey(it) }\n            .multiMap { \n                reads: it[0] \n                refs:  it[1][1..3] \n            }\n            .set { ch_prepared }\n    emit:\n        reads = ch_prepared.reads\n        refs = ch_prepared.refs\n}\n\nworkflow {\n    ch_in = getSingleInput()\n    ch_ref = getReferences('any')\n    \n    ch_ready = prepare_inputs(ch_in, ch_ref)\n    \n    module_segmented(ch_ready.reads, ch_ready.refs)\n}", "source_path": "modules/module_segmented.nf"}
{"id": "module_filtered_denovo", "content": "nextflow.enable.dsl=2\n\ninclude { step_1PP_filtering__bowtie } from '../steps/step_1PP_filtering__bowtie'\ninclude { step_2AS_denovo__spades } from '../steps/step_2AS_denovo__spades'\ninclude { extractKey } from '../functions/common.nf'\ninclude { getSingleInput;getReference } from '../functions/parameters.nf'\n\nworkflow module_filtered_denovo {\n    take: \n        reads\n        reference \n    main:\n        reads.cross(reference) { extractKey(it) }.multiMap { \n            reads: it[0] // riscd, reads\n            refs:  it[1][1..3] // riscd, code, path\n        }.set { readsAndReferences }\n\n        filtered = step_1PP_filtering__bowtie(readsAndReferences.reads, readsAndReferences.refs)       \n        assembled = step_2AS_denovo__spades(filtered)\n    emit:\n        assembled = assembled\n        filtered = filtered\n}\n\nworkflow {\n    module_filtered_denovo(getSingleInput(), getReference('fa'))\n}", "source_path": "modules/module_filtered_denovo.nf"}
{"id": "module_reads_processing", "content": "nextflow.enable.dsl=2\n\ninclude { step_0SQ_rawreads__fastq } from '../steps/step_0SQ_rawreads__fastq'\ninclude { step_1PP_trimming__trimmomatic } from '../steps/step_1PP_trimming__trimmomatic'\ninclude { step_1PP_trimming__fastp } from '../steps/step_1PP_trimming__fastp'\ninclude { step_3TX_class__kraken } from '../steps/step_3TX_class__kraken'\ninclude { getInput;hasFastqData;hasEnoughFastqData;isIlluminaPaired;isIonTorrent;isNanopore } from '../functions/parameters.nf'\ninclude { isBacterium } from '../functions/sampletypes.nf'\n\nworkflow module_reads_processing {\n    take: \n        rawReads\n    main:\n        rawReads.branch {\n            with_data: hasFastqData(it[1])\n            no_reads: true\n        }.set { ch_raw }\n\n        step_0SQ_rawreads__fastq(ch_raw.with_data)        \n\n        ch_raw.with_data.branch {\n            illumina: isIlluminaPaired(it[1])\n            ion: isIonTorrent(it[1])\n            nanopore: isNanopore(it[1])\n            other: true \n        }.set { ch_tech }\n\n        ch_tech.illumina.branch {\n            bacteria: isBacterium(it)\n            other: true \n        }.set { ch_illumina }\n\n        proc_trimmomatic = step_1PP_trimming__trimmomatic(ch_illumina.other)\n        \n        ch_fastp_in = ch_tech.ion.mix(ch_illumina.bacteria)\n        proc_fastp = step_1PP_trimming__fastp(ch_fastp_in)\n\n        ch_trimmed = proc_trimmomatic.trimmed.mix(proc_fastp.trimmed)\n\n        ch_trimmed.branch {\n            with_data: hasEnoughFastqData(it[1])\n            insufficient: true\n        }.set { ch_final }\n\n        step_3TX_class__kraken(ch_final.with_data)\n\n    emit:\n        no_reads = ch_raw.no_reads\n        trimmed_with_data = ch_final.with_data\n        insufficient_number_of_reads = ch_final.insufficient\n}\n\nworkflow {\n    module_reads_processing(getInput())\n}", "source_path": "modules/module_reads_processing.nf"}
{"id": "module_covid_emergency", "content": "nextflow.enable.dsl=2\n\ninclude { step_2AS_mapping__ivar } from '../steps/step_2AS_mapping__ivar'\ninclude { step_4TY_lineage__pangolin } from '../steps/step_4TY_lineage__pangolin'\ninclude { extractKey } from '../functions/common.nf'\ninclude { getSingleInput } from '../functions/parameters.nf'\n\ndef referenceCode = 'NC_045512.2'\ndef referencePath = \"${params.assets_dir}/module_covid_emergency/NC_045512.fasta\"\ndef referenceRiscd = '220308-020220308005121273-2AS_import-external'\n\nworkflow module_covid_emergency {\n    take: \n        trimmed\n    main:\n        trimmed.multiMap {\n            trimmed: it\n            reference: [ referenceRiscd, referenceCode, file(referencePath) ]\n        }.set { trAndRef }\n        \n        ivar_out = step_2AS_mapping__ivar(trAndRef.trimmed, trAndRef.reference)\n        step_4TY_lineage__pangolin(ivar_out.consensus)\n}\n\nworkflow {\n    module_covid_emergency(getSingleInput())\n}", "source_path": "modules/module_covid_emergency.nf"}
{"id": "module_wgs_bacteria", "content": "nextflow.enable.dsl=2\n\ninclude { step_2AS_denovo__shovill } from '../steps/step_2AS_denovo__shovill'\ninclude { getSingleInput } from '../functions/parameters.nf'\n\nworkflow module_wgs_bacteria {\n    take: \n      trimmedReads\n    main:\n        step_2AS_denovo__shovill(trimmedReads)\n    emit:\n        shovill_out = step_2AS_denovo__shovill.out\n}\n\nworkflow {\n    module_wgs_bacteria(getSingleInput())\n}", "source_path": "modules/module_wgs_bacteria.nf"}
{"id": "module_vdraft_light", "content": "nextflow.enable.dsl=2\n\ninclude { step_1PP_hostdepl__bowtie } from '../steps/step_1PP_hostdepl__bowtie'\ninclude { step_2AS_mapping__bowtie } from '../steps/step_2AS_mapping__bowtie'\ninclude { extractKey } from '../functions/common.nf'\ninclude { getSingleInput;getHostOptional;getReference } from '../functions/parameters.nf'\n\nworkflow module_vdraft_light {\n    take: \n        trimmedReads\n        host\n        reference\n    main:\n        trimmedReads.cross(host) { extractKey(it) }\n            .map { [ it[0][0], it[0][1], it[1][1] ] }\n            .branch {\n                with_host: it[1][1]\n                without_host: true\n            }\n            .set { ch_branched }\n\n        ch_depleted = step_1PP_hostdepl__bowtie(ch_branched.with_host)\n\n        ch_branched.without_host\n            .mix(ch_depleted)\n            .map { it[0,1] }\n            .set { ch_ready }\n\n        ch_ready.cross(reference) { extractKey(it) }\n            .multiMap { \n                reads: it[0]\n                refs:  it[1][1..3]\n            }\n            .set { ch_final }\n\n        step_2AS_mapping__bowtie(ch_final.reads, ch_final.refs)\n}\n\nworkflow {\n    ch_in = getSingleInput()\n    ch_host = getHostOptional()\n    ch_ref = getReference('fa')\n    module_vdraft_light(ch_in, ch_host, ch_ref)\n}", "source_path": "modules/module_vdraft_light.nf"}
{"id": "module_enterotoxin_saureus_finder", "content": "nextflow.enable.dsl=2\n\ninclude { step_2AS_denovo__unicycler } from '../steps/step_2AS_denovo__unicycler'\ninclude { step_4AN_AMR__blast } from '../steps/step_4AN_AMR__blast'\ninclude { getSingleInput;getGenusSpeciesOptional } from '../functions/parameters.nf'\ninclude { extractKey } from '../functions/common.nf'\n\nworkflow module_enterotoxin_saureus_finder {\n    take: \n        trimmed\n        genus_species\n    main:\n        assembly = step_2AS_denovo__unicycler(trimmed)\n\n        assembly.cross(genus_species) { extractKey(it) }\n            .multiMap { \n                assembly: it[0]\n                species: it[1]\n            }.set { assemblyAndSpecies }\n        step_4AN_AMR__blast(assemblyAndSpecies.assembly, assemblyAndSpecies.species)\n}\n\nworkflow {\n    module_enterotoxin_saureus_finder(getSingleInput(), getGenusSpeciesOptional())\n}", "source_path": "modules/module_enterotoxin_saureus_finder.nf"}
{"id": "step_3TX_species__mash", "content": "nextflow.enable.dsl=2\n\ninclude { stepInputs;parseMetadataFromFileName;executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getInput;isCompatibleWithSeqType } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '3TX_species'\ndef METHOD = 'mash' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\n\nworkflow step_3TX_species__mash {\n    take: \n      reads\n    main:\n      mash_out = mash(reads)\n}\n\nworkflow {\n    step_3TX_species__mash(getInput())\n}", "source_path": "steps/step_3TX_species__mash.nf"}
{"id": "step_2AS_mapping__medaka", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName; executionMetadata;extractKey;taskMemory;stepInputs;getRisCd;extractDsRef } from '../functions/common.nf'\ninclude { getSingleInput;getReference;isCompatibleWithSeqType } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_mapping'\ndef METHOD = 'medaka' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      getSingleInput()\n        .cross(getReference('fa')) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            refs:  it[1][1..3]\n        }\n        .set { prepared_data }\n    emit:\n      reads = prepared_data.reads\n      refs = prepared_data.refs\n}\n\nworkflow step_2AS_mapping__medaka {\n  take: \n    reads\n    reference \n  main:\n    medaka_out = medaka(reads, reference)\n    minmax_out = coverage_minmax(medaka_out.bam, METHOD)\n    coverage_plot(minmax_out.coverage_depth)\n    depth_out = samtools_depth(medaka_out.bam, METHOD)\n    ch_cov_keyed = depth_out.coverage.map { [extractDsRef(it), it] }\n    ch_con_keyed = medaka_out.consensus.map { [extractDsRef(it), it] }\n    ch_cov_con_crossed = ch_cov_keyed.cross(ch_con_keyed)\n    ch_cov_con_crossed.map { \n        def cov = it[0][1] \n        def con = it[1][1] \n        return [ cov[0], con[1], cov[1] ]\n    }.set { coverageRefAndConsensus }\n    \n    check_out = coverage_check(coverageRefAndConsensus, METHOD)\n    coverageBasic = check_out.coverage_basic\n    ch_extra_keyed = minmax_out.coverage_extra.map { [it[0] + \"-\" + it[1], it] }\n    ch_basic_keyed = coverageBasic.map { [it[0] + \"-\" + it[1], it] }\n    ch_checks_crossed = ch_extra_keyed.cross(ch_basic_keyed)\n    ch_checks_crossed.map { \n        def extra = it[0][1]\n        def basic = it[1][1]\n        return [ extra[0], extra[1], extra[2], basic[2] ]\n    }.set { crossedChecks }\n    coverage_check_merge(crossedChecks, METHOD)\n  emit:\n    consensus = medaka_out.consensus\n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_2AS_mapping__medaka(inputs.reads, inputs.refs)\n}", "source_path": "steps/step_2AS_mapping__medaka.nf"}
{"id": "step_2AS_mapping__bowtie", "content": "nextflow.enable.dsl=2\n\ninclude { extractDsRef;parseMetadataFromFileName;executionMetadata;extractKey;taskMemory;getEmpty } from '../functions/common.nf'\ninclude { getSingleInput;getReference;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_mapping'\ndef METHOD = 'bowtie' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      getSingleInput()\n        .cross(getReference('fa')) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            refs:  it[1][1..3]\n        }\n        .set { prepared_data }\n    emit:\n      reads = prepared_data.reads\n      refs = prepared_data.refs\n}\n\nworkflow step_2AS_mapping__bowtie {\n  take: \n    reads\n    reference \n  main:\n    bowtie_out = bowtie2(reads, reference)\n    samtools_out = samtools(bowtie_out.sam)\n    seqio_out = seqio(samtools_out.fq)\n    consensus = seqio_out.consensus\n    minmax_out = coverage_minmax(samtools_out.bam, 'bowtie')\n    coverage_plot(minmax_out.coverage_depth)\n    depth_out = samtools_depth(samtools_out.bam, 'bowtie')\n    ch_cov_keyed = depth_out.coverage.map { [extractDsRef(it), it] }\n    ch_con_keyed = consensus.map { [extractDsRef(it), it] }\n    ch_cov_con_crossed = ch_cov_keyed.cross(ch_con_keyed)\n    ch_cov_con_crossed.map { \n        def cov = it[0][1] \n        def con = it[1][1] \n        return [ cov[0], con[1], cov[1] ]\n    }.set { coverageRefAndConsensus }\n    check_out = coverage_check(coverageRefAndConsensus, 'bowtie')\n    coverageBasic = check_out.coverage_basic\n    ch_extra_keyed = minmax_out.coverage_extra.map { [it[0] + \"-\" + it[1], it] }\n    ch_basic_keyed = coverageBasic.map { [it[0] + \"-\" + it[1], it] }\n    ch_checks_crossed = ch_extra_keyed.cross(ch_basic_keyed)\n    ch_checks_crossed.map { \n        def extra = it[0][1]\n        def basic = it[1][1]\n        return [ extra[0], extra[1], extra[2], basic[2] ] \n    }.set { crossedChecks }\n    merge_out = coverage_check_merge(crossedChecks, 'bowtie')\n    grouped_merge = merge_out.coverage_merged.groupTuple(by: 0)\n    coverage_check_group(grouped_merge, 'bowtie')\n  emit:\n    consensus\n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_2AS_mapping__bowtie(inputs.reads, inputs.refs)\n}", "source_path": "steps/step_2AS_mapping__bowtie.nf"}
{"id": "step_4AN_AMR__abricate", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getInput } from '../functions/parameters.nf'\ninclude { stepInputs } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4AN_AMR'\ndef METHOD = 'abricate'\ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_4AN_AMR__abricate {\n    take: data\n    main:\n      abricate_out = abricate(data)\n}\n\nworkflow {\n    step_4AN_AMR__abricate(getInput())\n}", "source_path": "steps/step_4AN_AMR__abricate.nf"}
{"id": "step_2MG_denovo__metaspades", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;isIlluminaPaired;isCompatibleWithSeqType } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2MG_denovo'\ndef METHOD = 'metaspades' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_2MG_denovo__metaspades{\n    take: data\n    main:\n      spades_out = metaspades(data)\n      filter_out = assembly_filter(spades_out.scaffolds)\n      quast(filter_out.fasta)\n    emit:\n      assembled = filter_out.fasta\n}\n\nworkflow {\n    step_2MG_denovo__metaspades(getSingleInput())\n}", "source_path": "steps/step_2MG_denovo__metaspades.nf"}
{"id": "step_4AN_AMR__resfinder", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;param;isCompatibleWithSeqType } from '../functions/parameters.nf'\ninclude { stepInputs } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4AN_AMR'\ndef METHOD = 'resfinder'\ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_4AN_AMR__resfinder {\n    take: \n      reads\n      genus_species\n    main:\n      resfinder_out = resfinder(reads, genus_species)\n}\n\nworkflow {\n    step_4AN_AMR__resfinder(getSingleInput(),param('genus_species'))\n}", "source_path": "steps/step_4AN_AMR__resfinder.nf"}
{"id": "step_1PP_filtering__minimap2", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;stepInputs;extractKey } from '../functions/common.nf'\ninclude { getSingleInput;isCompatibleWithSeqType;getReference;getRisCd} from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_filtering'\ndef METHOD = 'minimap2' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      getSingleInput()\n        .cross(getReference('fa')) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            refs:  it[1][1..3]\n        }\n        .set { prepared_data }\n    emit:\n      reads = prepared_data.reads\n      refs = prepared_data.refs\n}\n\nworkflow step_1PP_filtering__minimap2 {\n    take: \n      reads\n      reference\n    main:\n      minimap_out = minimap2(reads, reference)\n      samtools_out = samtools(minimap_out.sam)\n    emit:\n      samtools_out.filtered  \n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_1PP_filtering__minimap2(inputs.reads, inputs.refs)\n}", "source_path": "steps/step_1PP_filtering__minimap2.nf"}
{"id": "step_4TY_cgMLST__chewbbaca", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;taskTime } from '../functions/common.nf'\ninclude { getInput;param;optionalOrDefault;isIonTorrent } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\nSPECIES_SCHEMA = [\n  listeria_monocytogenes : ['l_mono_chewie_1748_220623'],\n  escherichia_coli : ['e_coli_chewie_2360_210531'],\n  salmonella_enterica : ['s_enterica_chewie_3255_210531']\n]\n\nSCHEMAS = [\n  l_mono_chewie_1748_220623 : \"/schemas/Listeria_monocytogenes_Pasteur_cgMLST_2022-06-23T18_03_54.613576.zip\",\n  e_coli_chewie_2360_210531 : \"/schemas/Escherichia_coli_INNUENDO_wgMLST_2021-05-31T14_24_05.304225.zip\",\n  s_enterica_chewie_3255_210531 : \"/schemas/Salmonella_enterica_INNUENDO_cgMLST_2021-05-31T20_28_21.350919.zip\"\n]\n\nCHEWBBACA_SINGLE_END_PARAMS = [\n  'l_mono_chewie_1748_220623': ' --minimum-length 144 --st 0.1 --bsr 0.6 ',\n  'e_coli_chewie_2360_210531': ' --minimum-length 0 --st 0.01 --bsr 0.6 --genes-list /schemas/Escherichia_coli_INNUENDO_cgMLST_EFSA_filterlist.txt ',\n  's_enterica_chewie_3255_210531': ' --minimum-length 0 --st 0.01 --bsr 0.6 --genes-list /schemas/Salmonella_enterica_INNUENDO_cgMLST_EFSA_filterlist.txt '\n]\n\nCHEWBBACA_PAIRED_END_PARAMS = [\n  'l_mono_chewie_1748_220623': ' --minimum-length 144 ',\n  'e_coli_chewie_2360_210531': ' --minimum-length 0 --genes-list /schemas/Escherichia_coli_INNUENDO_cgMLST_EFSA_filterlist.txt ',\n  's_enterica_chewie_3255_210531': ' --minimum-length 0 --genes-list /schemas/Salmonella_enterica_INNUENDO_cgMLST_EFSA_filterlist.txt '\n]\n\ndef getExtraParams(schema) {\n  try {   \n    if (isIonTorrent(null)) {\n      if (CHEWBBACA_SINGLE_END_PARAMS.containsKey(schema)) return CHEWBBACA_SINGLE_END_PARAMS[schema]\n    } else {\n      if (CHEWBBACA_PAIRED_END_PARAMS.containsKey(schema)) return CHEWBBACA_PAIRED_END_PARAMS[schema]\n    }        \n    return ''\n  } catch(Throwable t) { exit 1, \"Error: ${t.asString()}\" } \n}\n\ndef ex = executionMetadata()\ndef STEP = '4TY_cgMLST'\ndef METHOD = 'chewbbaca' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\ndef getSchema(gsp, schema) {\n  try {  \n    def genus_species = gsp ? gsp.toLowerCase() : ''\n    def (genus, species) = genus_species.contains(\"_\") ? genus_species.split('_') : [ genus_species, null ]\n    def allowedSchemas = []\n    if (SPECIES_SCHEMA.containsKey(genus_species)) {\n      allowedSchemas =  SPECIES_SCHEMA.get(genus_species) \n    } else if (SPECIES_SCHEMA.containsKey(genus)) {\n      allowedSchemas = SPECIES_SCHEMA.get(genus)\n    }\n    if (!allowedSchemas) return null\n    if (!schema) return allowedSchemas[0] \n    if (allowedSchemas.contains(schema)) return schema\n    return null;      \n  } catch(Throwable t) { exit 1, \"Error: ${t.asString()}\" } \n}\n\nworkflow step_4TY_cgMLST__chewbbaca {\n    take: \n      assembly\n      genus_species\n      schema\n    main:\n      chewbbaca_out = chewbbaca(assembly, genus_species, schema)      \n      hashing(chewbbaca_out.alleles)\n      chewbbaca_check(chewbbaca_out.stats)\n}\n\nworkflow {\n    step_4TY_cgMLST__chewbbaca(getInput(), param('genus_species'), optionalOrDefault('schema', ''))\n}", "source_path": "steps/step_4TY_cgMLST__chewbbaca.nf"}
{"id": "step_4AN_AMR__staramr", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;isSpeciesSupported } from '../functions/common.nf'\ninclude { getSingleInput;param } from '../functions/parameters.nf'\ninclude { stepInputs;flattenPath } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4AN_AMR'\ndef METHOD = 'staramr' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\ndef GENUS_ALLOWED = [\n  'campylobacter'\n]\n\nworkflow step_4AN_AMR__staramr {\n    take: \n      assembly\n      genus_species\n    main:\n      staramr_out = staramr(assembly, genus_species)\n}\n\nworkflow {\n    step_4AN_AMR__staramr(getSingleInput(), param('genus_species'))\n}", "source_path": "steps/step_4AN_AMR__staramr.nf"}
{"id": "step_4TY_MLST__mlst", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getInput;param } from '../functions/parameters.nf'\ninclude { stepInputs } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4TY_MLST'\ndef METHOD = 'mlst' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_4TY_MLST__mlst {\n    take: \n      assembly\n    main:\n      mlst_out = mlst(assembly)\n}\n\nworkflow {\n  step_4TY_MLST__mlst(getInput())\n}", "source_path": "steps/step_4TY_MLST__mlst.nf"}
{"id": "step_1PP_trimming__chopper", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;taskTime } from '../functions/common.nf'\ninclude { getInput;isCompatibleWithSeqType;paramWrap;optWrap } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_trimming'\ndef METHOD = 'chopper' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_1PP_trimming__chopper {\n    take: \n      rawreads\n    main:\n      chopper_out = chopper(rawreads)\n      nanoplot(chopper_out.trimmed)\n    emit:\n      chopper_out.trimmed      \n}\n\nworkflow {\n    step_1PP_trimming__chopper(getInput())\n}", "source_path": "steps/step_1PP_trimming__chopper.nf"}
{"id": "step_4TY_lineage__westnile", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;_getSingleReference } from '../functions/parameters.nf'\ninclude { stepInputs;csv2map;getRisCd;parseRISCD } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4TY_lineage'\ndef METHOD = 'westnile' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nSTEP_ASSETS_DIR = \"${params.assets_dir}/${ENTRYPOINT}\"\ndef HCOV_THRESHOLD = params.step_4TY_lineage__westnile___threshold\ndef WESTNILE_LINEAGE_REFERENCES_PATH = \"${STEP_ASSETS_DIR}/westnile_lineage_references.json\"\nWESTNILE_LINEAGE_REFERENCES = new groovy.json.JsonSlurper().parseText(file(WESTNILE_LINEAGE_REFERENCES_PATH).text)\n\ndef getReferenceForLineage(lineageFile) {\n   try {        \n      def lineage = csv2map(lineageFile, \",\").lineage\n      def refData = WESTNILE_LINEAGE_REFERENCES.find { it.lineage == lineage }\n      return [ refData.ref_riscd, refData.ref_code, \"${STEP_ASSETS_DIR}/${refData.ref_path}\" ]\n   } catch(Throwable t) { exit 1, \"Error: ${t.asString()}\" }   \n}\n\ndef isValidLineage(lineageResult) {\n   try {        \n      def lineage = csv2map(lineageResult[1], \",\").lineage   \n      def notAssigned =  lineage == 'NA'\n      def notDetermined = lineage == 'ND'\n      return !notAssigned && !notDetermined\n   } catch(Throwable t) { exit 1, \"Error: ${t.asString()}\" }   \n}\n \ndef getWNVReferences() {\n   try {        \n      return Channel.fromList(WESTNILE_LINEAGE_REFERENCES.collect { [ it.ref_riscd, it.ref_code, \"${STEP_ASSETS_DIR}/${it.ref_path}\" ] } )\n   } catch(Throwable t) { exit 1, \"Error: ${t.asString()}\" }   \n}\n\nworkflow step_4TY_lineage__westnile {\n    take: \n      reads\n    main:\n      references = getWNVReferences()\n      comb = reads.combine(references)\n      \n      snippy_out = snippy(comb)\n      samtools_out = samtools_depth(snippy_out.bam)\n      \n      grouped_cov = samtools_out.coverage.groupTuple()\n      \n      lineage_out = lineage_selection(grouped_cov)\n    emit:\n      lineage = lineage_out.lineage.filter { isValidLineage(it) }\n}\n\nworkflow {  \n    step_4TY_lineage__westnile(getSingleInput())\n}", "source_path": "steps/step_4TY_lineage__westnile.nf"}
{"id": "step_1PP_trimming__trimmomatic", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;extractKey } from '../functions/common'\ninclude { getInput;isIonTorrent;isIlluminaPaired;isCompatibleWithSeqType } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_trimming'\ndef METHOD = 'trimmomatic' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_1PP_trimming__trimmomatic {\n    take: rawreads\n    main:\n      trimmed = trimmomatic(rawreads).fastq;\n      fastqc(trimmed)\n      readsCheckInput = rawreads.cross(trimmed) { extractKey(it) }.multiMap { \n        rawreads: it[0]\n        trimmed: it[1]\n      }      \n      sample_reads_check(readsCheckInput.rawreads, readsCheckInput.trimmed)\n    emit:\n      trimmed\n}\n\n\nworkflow {\n    step_1PP_trimming__trimmomatic(getInput())\n}", "source_path": "steps/step_1PP_trimming__trimmomatic.nf"}
{"id": "step_4TY_plasmid__mobsuite", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;param;isCompatibleWithSeqType } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4TY_plasmid'\ndef METHOD = 'mobsuite'\ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_4TY_plasmid__mobsuite {\n    take: \n      reads\n    main:\n      mobsuite_out = mobsuite(reads)\n    emit:\n      plasmids = mobsuite_out.plasmids\n}\n\nworkflow {\n    step_4TY_plasmid__mobsuite(getSingleInput())\n}", "source_path": "steps/step_4TY_plasmid__mobsuite.nf"}
{"id": "step_2AS_filtering__seqio", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\ninclude { param } from '../functions/parameters.nf'\n\nFILTERABLE_REFERENCES_PATH = param('step_2AS_filtering__seqio')\n\ndef ex = executionMetadata()\ndef STEP = '2AS_denovo'\ndef METHOD = 'spades' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\ndef isReferenceFilterable(refCode, _path) {\n    try {\n      def referencePath = (_path instanceof java.util.Collection) ? _path.flatten()[0] : _path\n      if (referencePath.empty) return false\n      return referencePath.toRealPath().toString().contains(FILTERABLE_REFERENCES_PATH)\n    } catch(Throwable t) { return false } \n}\n\nworkflow step_2AS_filtering__seqio {\n    take: \n      calls\n      assembly\n      reference\n    main:\n      filter(calls, assembly, reference)\n}", "source_path": "steps/step_2AS_filtering__seqio.nf"}
{"id": "step_1PP_trimming__fastp", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;taskTime } from '../functions/common.nf'\ninclude { getInput;isIonTorrent;isIlluminaPaired;isCompatibleWithSeqType } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd;extractKey } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_trimming'\ndef METHOD = 'fastp' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_1PP_trimming__fastp {\n    take: \n      rawreads\n    main:\n      trimmed = fastp(rawreads).trimmed\n\n      fastqc(trimmed)\n      readsCheckInput = rawreads.cross(trimmed) { extractKey(it) }.multiMap { \n        rawreads: it[0]\n        trimmed: it[1]\n      }      \n      sample_reads_check(readsCheckInput.rawreads, readsCheckInput.trimmed)\n\n    emit:\n      trimmed      \n}\n\nworkflow {\n    step_1PP_trimming__fastp(getInput())\n}", "source_path": "steps/step_1PP_trimming__fastp.nf"}
{"id": "step_3TX_class__kraken2", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { isSarsCov2;isPositiveControlSarsCov2;isNegativeControlSarsCov2 } from '../functions/sampletypes'\ninclude { param;getSingleInput;isIlluminaPaired;isCompatibleWithSeqType } from '../functions/parameters'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef KRAKEN2_DB = param('step_3TX_class__kraken2__db')\n\ndef ex = executionMetadata()\ndef STEP = '3TX_class'\ndef METHOD = 'kraken2' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_3TX_class__kraken2 {\n    take: reads\n    main:\n      kraken_out = kraken2(reads)\n      braken_out = braken2(kraken_out.report)\n     emit:\n       genus_report = braken_out.genus_report\n}\n\nworkflow {\n  step_3TX_class__kraken2(getSingleInput())\n}", "source_path": "steps/step_3TX_class__kraken2.nf"}
{"id": "step_4TY_lineage__pangolin", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getInput } from '../functions/parameters.nf'\ninclude { stepInputs } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4TY_lineage'\ndef METHOD = 'pangolin' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_4TY_lineage__pangolin {\n    take: \n      consensus\n    main:\n      pangolin_out = pangolin(consensus)\n}\n\nworkflow {\n    step_4TY_lineage__pangolin(getInput())\n}", "source_path": "steps/step_4TY_lineage__pangolin.nf"}
{"id": "step_4TY_flaA__flaA", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;isSpeciesSupported } from '../functions/common.nf'\ninclude { getInput;param } from '../functions/parameters.nf'\ninclude { stepInputs } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4TY_flaA'\ndef METHOD = 'flaA' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\ndef MLST_SCHEMA_NAME = 'flaA'\ndef GENUS_ALLOWED = [\n  'campylobacter'\n]\n\nworkflow step_4TY_flaA__flaA {\n    take: \n      assembly\n      genus_species\n    main:\n      mlst_out = mlst_flaa(assembly, genus_species)\n}\n\nworkflow {\n    step_4TY_flaA__flaA(getInput(), param('genus_species'))\n}", "source_path": "steps/step_4TY_flaA__flaA.nf"}
{"id": "step_1PP_filtering__krakentools", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;extractKey } from '../functions/common'\ninclude { getTrimmedReads;getParamTaxaId;getParamIncludeChildren;getParamIncludeParents;getKrakenResults } from '../functions/parameters.nf'\ninclude { stepInputs } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_filtering'\ndef METHOD = 'krakentools' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      getKrakenResults().cross(getTrimmedReads(false)) { extractKey(it) }.multiMap { \n        kraken: it[0]\n        trimmed: it[1]\n      }.set { krakenAndTrimmed }\n    \n    emit:\n      kraken = krakenAndTrimmed.kraken\n      trimmed = krakenAndTrimmed.trimmed\n}\n\nworkflow step_1PP_filtering__krakentools {\n    take: \n      kraken\n      trimmed\n      taxaid\n      include_children\n      include_parents\n    main:\n      krakentools(kraken, trimmed, taxaid, include_children, include_parents)\n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_1PP_filtering__krakentools(inputs.kraken, inputs.trimmed, getParamTaxaId(), getParamIncludeChildren(), getParamIncludeParents())\n}", "source_path": "steps/step_1PP_filtering__krakentools.nf"}
{"id": "step_4AN_AMR__filtering", "content": "nextflow.enable.dsl=2\n\ninclude { stepInputs;parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;param } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4AN_AMR'\ndef METHOD = 'filtering'\ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_4AN_AMR__filtering {\n    take: \n      data\n      coverage\n      identity\n    main:\n      filtering_out = abricate_filtering(data, coverage, identity)\n}\n\nworkflow {\n    step_4AN_AMR__filtering(getSingleInput(), param('coverage'), param('identity'))\n}", "source_path": "steps/step_4AN_AMR__filtering.nf"}
{"id": "step_2AS_denovo__spades", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_denovo'\ndef METHOD = 'spades' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_2AS_denovo__spades {\n    take: data\n    main:\n      denovo_out = denovo(data)\n      filter_out = assembly_filter(denovo_out.scaffolds)\n      quast(filter_out.fasta)\n    emit:\n      assembled = filter_out.fasta\n}\n\nworkflow {\n    step_2AS_denovo__spades(getSingleInput())\n}", "source_path": "steps/step_2AS_denovo__spades.nf"}
{"id": "step_1PP_filtering__bowtie", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName; executionMetadata;taskMemory;extractKey } from '../functions/common'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\ninclude { getSingleInput;getReference;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_filtering'\ndef METHOD = 'bowtie' \n\nworkflow prepare_inputs {\n    main:\n      getSingleInput()\n        .cross(getReference('fa')) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            refs:  it[1][1..3]\n        }\n        .set { prepared_data }\n    emit:\n      reads = prepared_data.reads\n      refs = prepared_data.refs\n}\n\nworkflow step_1PP_filtering__bowtie {\n    take: \n      reads\n      reference \n    main:\n      bowtie2(reads, reference) \n      samtools(bowtie2.out.sam)\n    emit:\n      samtools.out.filtered      \n}\n\nworkflow {\n    data = prepare_inputs()\n    step_1PP_filtering__bowtie(data.reads, data.refs)\n}", "source_path": "steps/step_1PP_filtering__bowtie.nf"}
{"id": "step_2AS_denovo__plasmidspades", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_denovo'\ndef METHOD = 'plasmidspades' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_2AS_denovo__plasmidspades {\n    take: data\n    main:\n      spades_out = plasmid_spades(data)\n      filter_out = assembly_filter(spades_out.scaffolds)\n      quast(filter_out.fasta)\n    emit:\n      assembled = filter_out.fasta\n}\n\nworkflow {\n    step_2AS_denovo__plasmidspades(getSingleInput())\n}", "source_path": "steps/step_2AS_denovo__plasmidspades.nf"}
{"id": "step_1PP_downsampling__bbnorm", "content": "nextflow.enable.dsl=2\n\ninclude { stepInputs;parseMetadataFromFileName;executionMetadata } from '../functions/common.nf'\ninclude { getSingleInput;param;isIlluminaPaired;isCompatibleWithSeqType } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_downsampling'\ndef METHOD = 'bbnorm' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_1PP_downsampling__bbnorm {\n    take: \n      reads\n      k\n      target\n    main:\n      bbnorm(reads, k, target)\n}\n\nworkflow {\n    step_1PP_downsampling__bbnorm(getSingleInput(), param('k'), param('target'))\n}", "source_path": "steps/step_1PP_downsampling__bbnorm.nf"}
{"id": "step_0SQ_rawreads__fastq", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory } from '../functions/common'\ninclude { getInput;isCompatibleWithSeqType;isIlluminaPaired } from '../functions/parameters.nf'\ninclude { stepInputs;parseRISCD } from '../functions/common.nf'\n\ndef ex = executionMetadata()\n\ndef STEP = '0SQ_rawreads'\ndef METHOD = 'fastq'\ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_0SQ_rawreads__fastq {\n    take: data\n    main:\n      fastqc(data)\n\n      nanoplot_out = nanoplot(data)\n      nanopore_reads_check(nanoplot_out.stats)\n}\n\nworkflow {\n  step_0SQ_rawreads__fastq(getInput())\n}", "source_path": "steps/step_0SQ_rawreads__fastq.nf"}
{"id": "step_3TX_class__kraken", "content": "nextflow.enable.dsl=2\n\ninclude { getEmpty;flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { isSarsCov2;isPositiveControlSarsCov2;isNegativeControlSarsCov2;isNGSMG16S } from '../functions/sampletypes'\ninclude { param;isFullOutput;getSingleInput;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef db_kraken=param('step_3TX_class__kraken__db_kraken')\ndef db_bracken=param('step_3TX_class__kraken__db_bracken')\ndef ex = executionMetadata()\ndef STEP = '3TX_class'\ndef METHOD = 'kraken' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_3TX_class__kraken {\n    take: reads\n    main:\n      kraken_out = kraken(reads) \n      braken_out = braken(kraken_out.report)\n     emit:\n       genus_report = braken_out.genus_report\n}\n\nworkflow {\n  step_3TX_class__kraken(getSingleInput())\n}", "source_path": "steps/step_3TX_class__kraken.nf"}
{"id": "step_3TX_class__confindr", "content": "nextflow.enable.dsl=2\n\ninclude { stepInputs;parseMetadataFromFileName;executionMetadata;isSpeciesSupported;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;param;isIlluminaPaired;isCompatibleWithSeqType } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '3TX_class'\ndef METHOD = 'confindr' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\ndef GENUS_ALLOWED = [\n  'escherichia',\n  'salmonella',\n  'listeria' \n]\n\nworkflow step_3TX_class__confindr {\n    take: \n      reads\n      genus_species\n    main:\n      confindr(reads, genus_species)\n}\n\nworkflow {\n    step_3TX_class__confindr(getSingleInput(),param('genus_species'))\n}", "source_path": "steps/step_3TX_class__confindr.nf"}
{"id": "step_1PP_generated__fasta2fastq", "content": "nextflow.enable.dsl=2\n\ninclude { stepInputs;parseMetadataFromFileName;executionMetadata;flattenPath } from '../functions/common.nf'\ninclude { getSingleInput } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_generated'\ndef METHOD = 'fasta2fastq' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_1PP_generated__fasta2fastq {\n    take: \n      reads\n    main:\n      fasta2fastq(reads)\n}\n\nworkflow {\n    step_1PP_generated__fasta2fastq(getSingleInput())\n}", "source_path": "steps/step_1PP_generated__fasta2fastq.nf"}
{"id": "step_1PP_hostdepl__bowtie", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common'\ninclude { param;getSingleInput;getHostUnkeyed;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef refDir = param('hosts_dir')\ndef ex = executionMetadata()\ndef STEP = '1PP_hostdepl'\ndef METHOD = 'bowtie' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      ch_input = getSingleInput()\n      ch_host = getHostUnkeyed()\n      \n      ch_combined = ch_input.combine(ch_host)\n    emit:\n      combined_inputs = ch_combined\n}\n\nworkflow step_1PP_hostdepl__bowtie {\n    take: \n      trimmedAndHost\n    main:\n      bowtie_out = bowtie2(trimmedAndHost)\n      samtools_out = samtools(bowtie_out.sam)\n    emit:\n      samtools_out.depleted      \n}\n\nworkflow {    \n    inputs = prepare_inputs()\n    step_1PP_hostdepl__bowtie(inputs.combined_inputs)    \n}", "source_path": "steps/step_1PP_hostdepl__bowtie.nf"}
{"id": "step_2AS_hybrid__unicycler", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;isIlluminaPaired;isCompatibleWithSeqType;getLongReads;param } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_hybrid'\ndef METHOD = 'unicycler' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_2AS_hybrid__unicycler {\n    take: \n      short_reads\n      long_reads\n    main:\n      unicycler_out = unicycler(short_reads, long_reads)\n      quast(unicycler_out.scaffolds)\n    emit:\n      scaffolds = unicycler_out.scaffolds\n}\n\nworkflow {  \n    step_2AS_hybrid__unicycler(getSingleInput(), getLongReads())\n}", "source_path": "steps/step_2AS_hybrid__unicycler.nf"}
{"id": "step_2AS_denovo__shovill", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;taskTime } from '../functions/common.nf'\ninclude { getSingleInput;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_denovo'\ndef METHOD = 'shovill' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_2AS_denovo__shovill {\n    take: rawreads\n    main:\n      shovill_out = shovill(rawreads)\n      shovill_se_out = shovill_se(rawreads)\n      \n      contigs = shovill_out.assembly.mix(shovill_se_out.assembly)\n      \n      quast(contigs)\n      \n      if (!params.skip_checkm) {\n        checkm(contigs)\n      }\n    emit:\n      assembly = contigs\n}\n\nworkflow {\n    step_2AS_denovo__shovill(getSingleInput())\n}", "source_path": "steps/step_2AS_denovo__shovill.nf"}
{"id": "step_3TX_species__vdabricate", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName; executionMetadata; taskMemory } from '../functions/common.nf'\ninclude { param;getInput } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef abricateDBDir = param('step_3TX_species__vdabricate__db')\ndef ex = executionMetadata()\ndef STEP = '3TX_species'\ndef METHOD = 'vdabricate' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      ch_combined = getInput().combine(['viruses_TREF'])\n    emit:\n      scaffoldsAbricatedb = ch_combined\n}\n\nworkflow step_3TX_species__vdabricate {\n    take: data\n    main:\n      abricate_out = abricate(data)\n    emit:\n      calls = abricate_out.calls\n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_3TX_species__vdabricate(inputs.scaffoldsAbricatedb)\n}", "source_path": "steps/step_3TX_species__vdabricate.nf"}
{"id": "step_1PP_hostdepl__minimap2", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName;executionMetadata;taskMemory;stepInputs;extractKey } from '../functions/common.nf'\ninclude { getSingleInput;isCompatibleWithSeqType;getHostReference;getRisCd } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '1PP_hostdepl'\ndef METHOD = 'minimap2' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      getSingleInput().cross(getHostReference()) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            host:  it[1]\n        }.set { input }\n    emit:\n      reads = input.reads\n      host = input.host\n}\n\nworkflow step_1PP_hostdepl__minimap2 {\n    take: \n      reads\n      host\n    main:\n      minimap_out = minimap2(reads, host)\n      samtools_out = samtools(minimap_out.sam)\n    emit:\n      samtools_out.depleted \n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_1PP_hostdepl__minimap2(inputs.reads, inputs.host)\n}", "source_path": "steps/step_1PP_hostdepl__minimap2.nf"}
{"id": "step_2AS_mapping__snippy", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata; extractKey;taskMemory;stepInputs } from '../functions/common.nf'\ninclude { getSingleInput;getReference;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_mapping'\ndef METHOD = 'snippy' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      getSingleInput()\n        .cross(getReference('fa')) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            refs:  it[1][1..3]\n        }\n        .set { prepared_data }\n    emit:\n      reads = prepared_data.reads\n      refs = prepared_data.refs\n}\n\nworkflow step_2AS_mapping__snippy {\n  take: \n    reads\n    reference \n  main:\n    snippy(reads, reference)\n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_2AS_mapping__snippy(inputs.reads, inputs.refs)\n}", "source_path": "steps/step_2AS_mapping__snippy.nf"}
{"id": "step_2AS_mapping__minimap2", "content": "nextflow.enable.dsl=2\n\ninclude { parseMetadataFromFileName; executionMetadata;extractKey;taskMemory;stepInputs;getRisCd;extractDsRef } from '../functions/common.nf'\ninclude { getSingleInput;getReference;isCompatibleWithSeqType } from '../functions/parameters.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_mapping'\ndef METHOD = 'minimap2' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow prepare_inputs {\n    main:\n      getSingleInput()\n        .cross(getReference('fa')) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            refs:  it[1][1..3]\n        }\n        .set { prepared_data }\n    emit:\n      reads = prepared_data.reads\n      refs = prepared_data.refs\n}\n\nworkflow step_2AS_mapping__minimap2 {\n  take: \n    reads\n    reference \n  main:\n    minimap_out = minimap2(reads, reference)\n    samtools_out = samtools(minimap_out.sam)\n    seqio_out = seqio(samtools_out.fq)\n    consensus = seqio_out.consensus\n    minmax_out = coverage_minmax(samtools_out.bam, METHOD)\n    coverage_plot(minmax_out.coverage_depth)\n    \n    depth_out = samtools_depth(samtools_out.bam, METHOD)\n    ch_cov_keyed = depth_out.coverage.map { [extractDsRef(it), it] }\n    ch_con_keyed = consensus.map { [extractDsRef(it), it] }\n    ch_cov_con_crossed = ch_cov_keyed.cross(ch_con_keyed)\n    ch_cov_con_crossed.map { \n        def cov = it[0][1] \n        def con = it[1][1]\n        return [ cov[0], con[1], cov[1] ]\n    }.set { coverageRefAndConsensus }\n    \n    check_out = coverage_check(coverageRefAndConsensus, METHOD)\n    coverageBasic = check_out.coverage_basic\n    ch_extra_keyed = minmax_out.coverage_extra.map { [it[0] + \"-\" + it[1], it] }\n    ch_basic_keyed = coverageBasic.map { [it[0] + \"-\" + it[1], it] }\n    ch_checks_crossed = ch_extra_keyed.cross(ch_basic_keyed)\n    ch_checks_crossed.map { \n        def extra = it[0][1]\n        def basic = it[1][1]\n        return [ extra[0], extra[1], extra[2], basic[2] ]\n    }.set { crossedChecks }\n    coverage_check_merge(crossedChecks, METHOD)\n\n  emit:\n    consensus = consensus\n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_2AS_mapping__minimap2(inputs.reads, inputs.refs)\n}", "source_path": "steps/step_2AS_mapping__minimap2.nf"}
{"id": "step_2AS_denovo__unicycler", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;isIlluminaPaired;isCompatibleWithSeqType } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_denovo'\ndef METHOD = 'unicycler' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_2AS_denovo__unicycler {\n    take: data\n    main:\n      unicycler_out = unicycler(data)\n      filter_out = assembly_filter(unicycler_out.scaffolds)\n      quast(filter_out.fasta)\n    emit:\n      assembled = filter_out.fasta       \n}\n\nworkflow {\n    step_2AS_denovo__unicycler(getSingleInput())\n}", "source_path": "steps/step_2AS_denovo__unicycler.nf"}
{"id": "step_2AS_mapping__ivar", "content": "nextflow.enable.dsl=2\n\ninclude { extractDsRef;getEmpty;flattenPath; parseMetadataFromFileName; executionMetadata; extractKey;taskMemory } from '../functions/common.nf'\ninclude { getSingleInput;getReferences;getReferenceCodes;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent;isSegmentedMapping } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '2AS_mapping'\ndef METHOD = 'ivar' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\ndef getExDt(reference, ex) {\n    try {        \n      def reflist = getReferenceCodes()\n      if (reflist.size() < 2 || !reference || !reflist.contains(reference)) return ex.dt\n      return ex.dt + reflist.indexOf(reference)\n    } catch(Throwable t) { return ex.dt }\n}\n\ndef canBeAggregated(actual) {\n    try {        \n      def expected = getReferenceCodes()\n      if (expected.size() < 2) return false\n      if (actual.size() != expected.size()) return false\n      if (actual.any {!expected.contains(it)}) return false\n      return true\n    } catch(Throwable t) { return false }\n}\n\nworkflow prepare_inputs {\n    main:\n      getSingleInput()\n        .cross(getReference('fa')) { extractKey(it) }\n        .multiMap { \n            reads: it[0]\n            refs:  it[1][1..3]\n        }\n        .set { prepared_data }\n    emit:\n      reads = prepared_data.reads\n      refs = prepared_data.refs\n}\n\nworkflow step_2AS_mapping__ivar {\n  take: \n    reads\n    reference \n  main:\n    snippy_out = snippy(reads, reference)\n    pileup_out = samtools_pileup(snippy_out.bam)\n    ivar_out = ivar(pileup_out.pileup)\n    consensus = ivar_out.consensus\n    minmax_out = coverage_minmax(snippy_out.bam, 'vdsnippy')\n    coverage_plot(minmax_out.coverage_depth)\n    depth_out = samtools_depth(snippy_out.bam, 'vdsnippy')\n    ch_cov_keyed = depth_out.coverage.map { [extractDsRef(it), it] }\n    ch_con_keyed = consensus.map { [extractDsRef(it), it] }\n    ch_cov_con_crossed = ch_cov_keyed.cross(ch_con_keyed)\n    ch_cov_con_crossed.map { \n        def cov = it[0][1] \n        def con = it[1][1] \n        return [ cov[0], con[2], cov[1] ]\n    }.set { coverageRefAndConsensus }\n    check_out = coverage_check(coverageRefAndConsensus, 'ivar')\n    coverageBasic = check_out.coverage_basic\n    ch_extra_keyed = minmax_out.coverage_extra.map { [it[0] + \"-\" + it[1], it] }\n    ch_basic_keyed = coverageBasic.map { [it[0] + \"-\" + it[1], it] }\n    ch_checks_crossed = ch_extra_keyed.cross(ch_basic_keyed)\n    ch_checks_crossed.map { \n        def extra = it[0][1]\n        def basic = it[1][1]\n        return [ extra[0], extra[1], extra[2], basic[2] ]\n    }.set { crossedChecks }\n    merge_out = coverage_check_merge(crossedChecks, 'vdsnippy')\n    grouped_merge = merge_out.coverage_merged.groupTuple(by: 0)\n    coverage_check_group(grouped_merge, 'vdsnippy')\n    ch_reads_keyed = reads.map { [extractKey(it), it] }\n    ch_con_keyed_for_agg = consensus.map { [extractKey(it), it] }\n    ch_con_grouped = ch_con_keyed_for_agg.groupTuple()\n    ch_agg_crossed = ch_reads_keyed.cross(ch_con_grouped)\n    ch_agg_crossed.map {\n         def r = it[0][1]\n         def c_group = it[1][1]\n         def refs = c_group.collect { it[1] }\n         def paths = c_group.collect { it[2] }\n         return [ r[0], refs, paths ]\n    }.set { consensus_to_aggregate }\n    aggregate(consensus_to_aggregate)\n  emit:\n    consensus = consensus.map { it[0,2] }\n    coverage_depth = minmax_out.coverage_depth\n}\n\nworkflow {\n    inputs = prepare_inputs()\n    step_2AS_mapping__ivar(inputs.reads, inputs.refs)\n}", "source_path": "steps/step_2AS_mapping__ivar.nf"}
{"id": "step_3TX_species__kmerfinder", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata; csv2map; extractKey;taskMemory } from '../functions/common.nf'\ninclude { param;getInput } from '../functions/parameters.nf'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\nKMERFINDER_SPECIES_DIR = param('step_3TX_species__kmerfinder__db')\nKMERFINDER_REFERENCE_DIR = \"${KMERFINDER_SPECIES_DIR}/Bacteria/Fasta/\"\n\ndef ex = executionMetadata()\ndef STEP = '3TX_species'\ndef METHOD = 'kmerfinder' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\ndef getBacterialReferencePath(checkFile) {\n    try {\n      def bacterialReferenceId = csv2map(checkFile, \"\\\\t\").assembly_accBacteria\n      return [ '-', bacterialReferenceId, file(\"${KMERFINDER_REFERENCE_DIR}/${bacterialReferenceId}*.fa\") ] \n    } catch(Throwable t) { exit 1, \"Error: ${t.asString()}\" }\n}\n\ndef getCalculatedSpecies(checkFile) {\n    try {\n      return csv2map(checkFile, \"\\\\t\").speciesAssigned\n    } catch(Throwable t) { exit 1, \"Error: ${t.asString()}\" }\n}\n\nworkflow step_3TX_species__kmerfinder {\n    take: data\n    main:\n      kmerfinder_out = kmerfinder(data)\n      \n      assigned_species = kmerfinder_out.check.map { \n          [ it[0], getCalculatedSpecies(it[1]), getBacterialReferencePath(it[1]) ] \n      }\n    emit:\n      assigned_species = assigned_species\n}\n\nworkflow {\n    step_3TX_species__kmerfinder(getInput())\n}", "source_path": "steps/step_3TX_species__kmerfinder.nf"}
{"id": "step_4AN_genes__prokka", "content": "nextflow.enable.dsl=2\n\ninclude { flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory;extractKey } from '../functions/common.nf'\ninclude { getInput;getKingdom;getReferenceOptional;checkEnum } from '../functions/parameters.nf'\ninclude { stepInputs } from '../functions/common.nf'\n\ndef ex = executionMetadata()\ndef STEP = '4AN_genes'\ndef METHOD = 'prokka'\ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nenum KINGDOM {\n  Viruses, Bacteria, Archaea, Mitochondria\n}\n\nworkflow prepare_inputs {\n    main:\n      getInput()\n        .cross(getKingdom()) { extractKey(it) }\n        .cross(getReferenceOptional('gb')) { extractKey(it) }\n        .map { it.flatten() }  // [ riscd assembly ds kingdom ds riscd_ref refid refpath]\n        .map { \n            [ it[0], it[1], it[3], it[5], it[6], it[7] ]\n        }\n        .set { input }\n    emit:\n      input\n}\n\nworkflow step_4AN_genes__prokka {\n    take: \n      data\n    main:\n      prokka_out = prokka(data)\n}\n\nworkflow {\n  input = prepare_inputs()\n  step_4AN_genes__prokka(input)\n}", "source_path": "steps/step_4AN_genes__prokka.nf"}
{"id": "step_3TX_class__centrifuge", "content": "nextflow.enable.dsl=2\n\ninclude { getEmpty;flattenPath; parseMetadataFromFileName; executionMetadata;taskMemory } from '../functions/common.nf'\ninclude { param;isFullOutput;getSingleInput;isIlluminaPaired;isCompatibleWithSeqType;isIonTorrent } from '../functions/parameters'\ninclude { stepInputs;getRisCd } from '../functions/common.nf'\n\ndef DB_PATH=param('step_3TX_class__centrifuge__db_path')\ndef DB_NAME=param('step_3TX_class__centrifuge__db_name')\ndef ex = executionMetadata()\ndef STEP = '3TX_class'\ndef METHOD = 'centrifuge' \ndef ENTRYPOINT = \"step_${STEP}__${METHOD}\"\n\nworkflow step_3TX_class__centrifuge {\n    take: reads\n    main: \n      centrifuge_out = centrifuge(reads)\n      import_taxa(centrifuge_out.reports)\n}\n\nworkflow {\n  step_3TX_class__centrifuge(getSingleInput())\n}", "source_path": "steps/step_3TX_class__centrifuge.nf"}
